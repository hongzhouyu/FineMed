{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InsGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "\n",
    "# InsGen\n",
    "with open('output_list/ins_gen_output_list.json', 'r') as f:\n",
    "    output_list = json.load(f)\n",
    "\n",
    "print(len(output_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"question1\": \"What factors contribute to the low efficiency of cationic lipid-mediated gene transduction in polarized and differentiated airway epithelial cells, and how might these barriers be overcome to improve gene therapy for airway diseases such as cystic fibrosis?\",\\n    \"question2\": \"How do the results of gene transduction using GL-67:pDNA complexes in the nasal epithelium of cystic fibrosis transgenic mice compare to those observed in the lungs, and what implications do these differences have for the development of gene therapy strategies for cystic fibrosis?\"\\n}'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "存在解析失败\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a list to store successfully parsed JSON data and success serial numbers\n",
    "data = []\n",
    "successful_indexes = []\n",
    "flag = 0\n",
    "\n",
    "# Parsing JSON using list comprehensions, skipping items with errors\n",
    "for idx, item in enumerate(output_list):\n",
    "    try:\n",
    "        # Try parsing JSON\n",
    "        parsed_item = json.loads(item)\n",
    "        data.append(parsed_item)\n",
    "        successful_indexes.append(idx)  # Save the sequence number of the successful analysis\n",
    "    except json.JSONDecodeError:\n",
    "        # If parsing fails, print an error message and skip the current item.\n",
    "        # print(item)\n",
    "        flag = 1\n",
    "        continue\n",
    "\n",
    "if flag:\n",
    "    print(\"There is a parsing failure\")\n",
    "len(output_list) - len(successful_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question1', 'question2'],\n",
      "    num_rows: 209971\n",
      "})\n",
      "Dataset({\n",
      "    features: ['question'],\n",
      "    num_rows: 209971\n",
      "})\n",
      "Dataset({\n",
      "    features: ['question'],\n",
      "    num_rows: 209971\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 209971/209971 [00:00<00:00, 471003.93 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 209971/209971 [00:00<00:00, 441929.84 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Create datasets using the datasets library\n",
    "dataset = Dataset.from_list(data)\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "question1 = dataset[\"question1\"]\n",
    "question1_dict = {\"question\": question1}\n",
    "question1_set = Dataset.from_dict(question1_dict)\n",
    "print(question1_set)\n",
    "\n",
    "question2 = dataset[\"question2\"]\n",
    "question2_dict = {\"question\": question2}\n",
    "question2_set = Dataset.from_dict(question2_dict)\n",
    "print(question2_set)\n",
    "\n",
    "question1_set.save_to_disk(\"instructions/gen_ins/ins1\")\n",
    "question2_set.save_to_disk(\"instructions/gen_ins/ins2\")\n",
    "\n",
    "np.save('instructions/gen_ins/successful_indexes.npy', successful_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How do the results of gene transduction using GL-67:pDNA complexes in the nasal epithelium of cystic fibrosis transgenic mice compare to those observed in the lungs, and what implications do these differences have for the development of gene therapy strategies for cystic fibrosis?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "\n",
    "# Scoring\n",
    "with open('output_list/scoring_1.json', 'r') as f:\n",
    "    output_list = json.load(f)\n",
    "# with open('output_list/scoring_2.json', 'r') as f:\n",
    "#     output_list = json.load(f)\n",
    "\n",
    "print(len(output_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a list to store successfully parsed JSON data and success serial numbers\n",
    "data = []\n",
    "successful_indexes = []\n",
    "flag = 0\n",
    "\n",
    "# Parsing JSON using list comprehensions, skipping items with errors\n",
    "for idx, item in enumerate(output_list):\n",
    "    try:\n",
    "        # Try parsing JSON\n",
    "        parsed_item = json.loads(item)\n",
    "        data.append(parsed_item)\n",
    "        successful_indexes.append(idx)  # Save the sequence number of the successful analysis\n",
    "    except json.JSONDecodeError:\n",
    "        # If parsing fails, print an error message and skip the current item.\n",
    "        # print(item)\n",
    "        flag = 1\n",
    "        continue\n",
    "\n",
    "if flag:\n",
    "    print(\"There is a parsing failure\")\n",
    "len(output_list) - len(successful_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quality': 7,\n",
       " 'difficulty': 6,\n",
       " 'relevance_to_medicine': 5,\n",
       " 'mention_specific_details': 'True'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['quality', 'difficulty', 'relevance_to_medicine', 'mention_specific_details', 'ids'],\n",
      "    num_rows: 5000\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 5000/5000 [00:00<00:00, 471026.66 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ins_score_set = Dataset.from_list(data)\n",
    "print(ins_score_set)\n",
    "ins_score_set.save_to_disk(\"scoring/ins1_score\")\n",
    "# ins_score_set.save_to_disk(\"scoring/ins2_score\")\n",
    "np.save('scoring/successful_indexes1.npy', successful_indexes)\n",
    "# np.save('scoring/successful_indexes2.npy', successful_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 {\n",
      "    \"answer1\": \"Financial penalties for non-compliance by healthcare entities can have significant impacts on the quality and accessibility of healthcare services. These penalties, often imposed for violations of regulatory standards such as patient privacy (HIPAA) or quality of care, can lead to financial strain on healthcare facilities. This strain can result in reduced resources for patient care, fewer staff, and less investment in essential medical equipment and training, which can directly affect the quality of care provided. For under-resourced facilities, these penalties can be particularly detrimental, as they often have limited financial reserves to begin with. To ensure these penalties do not disproportionately affect under-resourced facilities, several measures can be taken. Firstly, regulatory bodies can provide technical assistance and training to help these facilities understand and comply with regulations. Secondly, a graduated penalty system can be implemented, where the severity of penalties is proportional to the severity and frequency of violations. Additionally, financial incentives can be offered for compliance, such as grants or subsidies for improving infrastructure and training. Lastly, community partnerships can be fostered to provide additional support and resources to these facilities, helping them maintain high standards of care without facing insurmountable financial burdens.\",\n",
      "    \"answer2\": \"The imposition of financial penalties on healthcare entities for non-compliance can have both positive and negative impacts on the quality and accessibility of healthcare services. On the positive side, these penalties can act as a strong deterrent against non-compliance, encouraging facilities to adhere to regulatory standards and thereby potentially improving the overall quality of care. However, the negative impacts are more pronounced, especially for under-resourced facilities. These penalties can lead to budget constraints, which may force facilities to cut costs in critical areas such as staffing, equipment, and training, thereby reducing the quality of care. Moreover, the financial strain can limit the accessibility of services, as facilities may have to reduce the number of patients they can serve or even close down. To mitigate these adverse effects, several measures can be implemented. One approach is to provide targeted financial support to under-resourced facilities to help them meet compliance requirements. This can include grants, low-interest loans, or subsidies. Another measure is to offer technical assistance and training programs to help these facilities understand and implement the necessary compliance measures. Additionally, a risk-adjusted penalty system can be adopted, where the penalties are adjusted based on the facility's financial capacity and the severity of the violation. Finally, fostering collaborations between government agencies, non-profits, and private sector organizations can provide a support network that helps under-resourced facilities navigate regulatory requirements and maintain high standards of care.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "\n",
    "# Scoring\n",
    "with open('output_list/res_output_list_common.json', 'r') as f:\n",
    "    output_list = json.load(f)\n",
    "\n",
    "# with open('output_list/res_output_list_complex1.json', 'r') as f:\n",
    "#     output_list = json.load(f)\n",
    "# with open('output_list/res_output_list_complex2.json', 'r') as f:\n",
    "#     output_list = json.load(f)\n",
    "print(len(output_list), output_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# common parses, comlex does not parse\n",
    "# Initialize a list to store successfully parsed JSON data and success serial numbers\n",
    "data = []\n",
    "successful_indexes = []\n",
    "flag = 0\n",
    "\n",
    "# Parsing JSON using list comprehensions, skipping items with errors\n",
    "for idx, item in enumerate(output_list):\n",
    "    try:\n",
    "        # Try parsing JSON\n",
    "        parsed_item = json.loads(item)\n",
    "        data.append(parsed_item)\n",
    "        successful_indexes.append(idx)  # Save the sequence number of the successful analysis\n",
    "    except json.JSONDecodeError:\n",
    "        # If parsing fails, print an error message and skip the current item.\n",
    "        # print(item)\n",
    "        flag = 1\n",
    "        continue\n",
    "\n",
    "if flag:\n",
    "    print(\"There is a parsing failure\")\n",
    "len(output_list) - len(successful_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['answer1', 'answer2'],\n",
      "    num_rows: 95\n",
      "})\n",
      "Dataset({\n",
      "    features: ['answer'],\n",
      "    num_rows: 95\n",
      "})\n",
      "Dataset({\n",
      "    features: ['answer'],\n",
      "    num_rows: 95\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 95/95 [00:00<00:00, 9564.08 examples/s] \n",
      "Saving the dataset (1/1 shards): 100%|██████████| 95/95 [00:00<00:00, 10861.63 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# common:\n",
    "dataset = Dataset.from_list(data)\n",
    "print(dataset)\n",
    "\n",
    "answer1 = dataset[\"answer1\"]\n",
    "answer1_dict = {\"answer\": answer1}\n",
    "answer1_set = Dataset.from_dict(answer1_dict)\n",
    "print(answer1_set)\n",
    "\n",
    "answer2 = dataset[\"answer2\"]\n",
    "answer2_dict = {\"answer\": answer2}\n",
    "answer2_set = Dataset.from_dict(answer2_dict)\n",
    "print(answer2_set)\n",
    "\n",
    "answer1_set.save_to_disk(\"gen_response/res1\")\n",
    "answer2_set.save_to_disk(\"gen_response/res2\")\n",
    "\n",
    "np.save('gen_response/successful_indexes.npy', successful_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['answer'],\n",
      "    num_rows: 1\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 177.04 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# complex: \n",
    "answer_dict = {\"answer\": output_list}\n",
    "answer_set = Dataset.from_dict(answer_dict)\n",
    "print(answer_set)\n",
    "# The initial idea is to generate two responses for the complex instruction, and then use RM to score and filter.\n",
    "answer_set.save_to_disk(\"/home/ubuntu/test_disk/res1_qwq\")\n",
    "# answer_set.save_to_disk(\"/home/ubuntu/test_disk/res2_qwq\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
